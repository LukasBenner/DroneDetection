{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24a3ea43",
   "metadata": {},
   "source": [
    "# RF-DETR Fine-tuning on Google Colab\n",
    "\n",
    "This notebook demonstrates how to fine-tune RF-DETR for drone detection using GPU acceleration on Google Colab.\n",
    "\n",
    "## Prerequisites\n",
    "1. Enable GPU runtime: Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "2. Upload your dataset to Google Drive or prepare it for upload to Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e2fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Device memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ GPU not available. Please enable GPU runtime: Runtime > Change runtime type > Hardware accelerator > GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install rfdetr==1.2.1\n",
    "!pip install supervision==0.26.1\n",
    "!pip install roboflow\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b5d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (optional - if your dataset is stored there)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# If dataset is in Google Drive, set the path accordingly\n",
    "# dataset_location = \"/content/drive/MyDrive/path/to/your/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca540f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Upload dataset as zip file\n",
    "# Uncomment and run this cell if you want to upload a dataset zip file\n",
    "\n",
    "# from google.colab import files\n",
    "# import zipfile\n",
    "# import os\n",
    "\n",
    "# print(\"Please upload your dataset zip file...\")\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# # Extract the uploaded zip file\n",
    "# for filename in uploaded.keys():\n",
    "#     if filename.endswith('.zip'):\n",
    "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#             zip_ref.extractall('/content/')\n",
    "#         print(f\"Extracted {filename}\")\n",
    "#         # Remove the zip file to save space\n",
    "#         os.remove(filename)\n",
    "\n",
    "# dataset_location = \"/content/dataset\"  # Adjust path as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558cf77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Download dataset from URL (if available)\n",
    "# Uncomment and modify this cell if your dataset is available via URL\n",
    "\n",
    "# import requests\n",
    "# import zipfile\n",
    "# from io import BytesIO\n",
    "\n",
    "# dataset_url = \"YOUR_DATASET_URL_HERE\"  # Replace with your dataset URL\n",
    "# response = requests.get(dataset_url)\n",
    "# with zipfile.ZipFile(BytesIO(response.content)) as zip_ref:\n",
    "#     zip_ref.extractall('/content/')\n",
    "\n",
    "# dataset_location = \"/content/dataset\"  # Adjust path as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1031bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Download from Roboflow (if your dataset is hosted there)\n",
    "# Uncomment and modify this cell if using Roboflow\n",
    "\n",
    "# import roboflow\n",
    "# from roboflow import Roboflow\n",
    "\n",
    "# rf = Roboflow(api_key=\"YOUR_API_KEY\")  # Replace with your API key\n",
    "# project = rf.workspace(\"YOUR_WORKSPACE\").project(\"YOUR_PROJECT\")  # Replace with your details\n",
    "# dataset = project.version(1).download(\"coco\", location=\"/content\")\n",
    "\n",
    "# dataset_location = dataset.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c495ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset location manually if using any of the above methods\n",
    "# Adjust this path based on where your dataset was extracted/downloaded\n",
    "dataset_location = \"./dataset\"  # Change this to match your dataset location\n",
    "\n",
    "# Verify dataset structure\n",
    "import os\n",
    "if os.path.exists(dataset_location):\n",
    "    print(f\"Dataset found at: {dataset_location}\")\n",
    "    print(\"Dataset structure:\")\n",
    "    for root, dirs, files in os.walk(dataset_location):\n",
    "        level = root.replace(dataset_location, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files[:5]:  # Show first 5 files only\n",
    "            print(f\"{subindent}{file}\")\n",
    "        if len(files) > 5:\n",
    "            print(f\"{subindent}... and {len(files)-5} more files\")\n",
    "else:\n",
    "    print(f\"⚠️ Dataset not found at {dataset_location}\")\n",
    "    print(\"Please upload your dataset using one of the methods above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174650f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RF-DETR\n",
    "from rfdetr import RFDETRMedium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f88af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "# The model will automatically use GPU if available\n",
    "model = RFDETRMedium()\n",
    "\n",
    "# Training parameters optimized for Colab\n",
    "# Adjust batch_size based on your GPU memory\n",
    "# For Colab's free T4 GPU, batch_size=4-8 should work well\n",
    "model.train(\n",
    "    dataset_dir=dataset_location, \n",
    "    epochs=10,              # Increased epochs for better training\n",
    "    batch_size=4,           # Reduced for better GPU memory usage\n",
    "    grad_accum_steps=4,     # Increased to simulate larger batch size\n",
    "    lr=1e-3,                # Slightly reduced learning rate\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"  # Explicitly set device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ef863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save_model(\"rf_detr_drone_detection.pth\")\n",
    "print(\"Model saved as 'rf_detr_drone_detection.pth'\")\n",
    "\n",
    "# Download the model to your local machine\n",
    "from google.colab import files\n",
    "files.download(\"rf_detr_drone_detection.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f576e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset for evaluation\n",
    "import supervision as sv\n",
    "\n",
    "ds = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=f\"{dataset_location}/test\",\n",
    "    annotations_path=f\"{dataset_location}/test/_annotations.coco.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a35fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize model for inference\n",
    "model.optimize_for_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a843edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs ground truth\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images = []\n",
    "titles = []\n",
    "\n",
    "# Reduce number of images for faster processing in Colab\n",
    "num_samples = min(5, len(ds))  # Show 5 samples or less if dataset is smaller\n",
    "\n",
    "for i in range(num_samples):\n",
    "    path, image, annotations = ds[i]\n",
    "    image = Image.open(path)\n",
    "    \n",
    "    # Get predictions\n",
    "    detections = model.predict(image, threshold=0.5)\n",
    "\n",
    "    # Calculate optimal visualization parameters\n",
    "    text_scale = sv.calculate_optimal_text_scale(resolution_wh=image.size)\n",
    "    thickness = sv.calculate_optimal_line_thickness(resolution_wh=image.size)\n",
    "    color = sv.ColorPalette.from_hex([\n",
    "        \"#ffff00\", \"#ff9b00\", \"#ff66ff\", \"#3399ff\", \"#ff66b2\", \"#ff8080\",\n",
    "        \"#b266ff\", \"#9999ff\", \"#66ffff\", \"#33ff99\", \"#66ff66\", \"#99ff00\"\n",
    "    ])\n",
    "\n",
    "    # Create annotators\n",
    "    bbox_annotator = sv.BoxAnnotator(color=color, thickness=thickness)\n",
    "    label_annotator = sv.LabelAnnotator(\n",
    "        color=color,\n",
    "        text_color=sv.Color.BLACK,\n",
    "        text_scale=text_scale\n",
    "    )\n",
    "\n",
    "    # Create labels\n",
    "    annotations_labels = [\n",
    "        f\"{ds.classes[class_id]}\"\n",
    "        for class_id in annotations.class_id\n",
    "    ]\n",
    "\n",
    "    detections_labels = [\n",
    "        f\"{ds.classes[class_id]} {confidence:.2f}\"\n",
    "        for class_id, confidence\n",
    "        in zip(detections.class_id, detections.confidence)\n",
    "    ]\n",
    "\n",
    "    # Annotate ground truth\n",
    "    annotation_image = image.copy()\n",
    "    annotation_image = bbox_annotator.annotate(annotation_image, annotations)\n",
    "    annotation_image = label_annotator.annotate(annotation_image, annotations, annotations_labels)\n",
    "\n",
    "    # Annotate predictions\n",
    "    detections_image = image.copy()\n",
    "    detections_image = bbox_annotator.annotate(detections_image, detections)\n",
    "    detections_image = label_annotator.annotate(detections_image, detections, detections_labels)\n",
    "\n",
    "    images.extend([annotation_image, detections_image])\n",
    "    titles.extend([f\"Ground Truth {i+1}\", f\"Prediction {i+1}\"])\n",
    "\n",
    "# Plot results\n",
    "sv.plot_images_grid(images=images, grid_size=(num_samples, 2), titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb598de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance (optional)\n",
    "# This cell provides basic evaluation metrics\n",
    "\n",
    "from supervision import MeanAveragePrecision\n",
    "\n",
    "# Collect all predictions and ground truths\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "print(\"Evaluating model on test set...\")\n",
    "for i in range(len(ds)):\n",
    "    path, image, annotations = ds[i]\n",
    "    image = Image.open(path)\n",
    "    \n",
    "    # Get predictions\n",
    "    detections = model.predict(image, threshold=0.3)  # Lower threshold for evaluation\n",
    "    \n",
    "    all_predictions.append(detections)\n",
    "    all_targets.append(annotations)\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Processed {i + 1}/{len(ds)} images\")\n",
    "\n",
    "# Calculate mAP\n",
    "map_metric = MeanAveragePrecision()\n",
    "map_result = map_metric.update(all_predictions, all_targets).compute()\n",
    "\n",
    "print(f\"\\nEvaluation Results:\")\n",
    "print(f\"mAP@0.5: {map_result.map50:.3f}\")\n",
    "print(f\"mAP@0.5:0.95: {map_result.map50_95:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View TensorBoard logs (if available)\n",
    "# Uncomment if RF-DETR generates TensorBoard logs\n",
    "\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ./output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5634fd",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Model Performance**: If the model performance is not satisfactory, consider:\n",
    "   - Increasing the number of epochs\n",
    "   - Adjusting learning rate\n",
    "   - Data augmentation\n",
    "   - Fine-tuning hyperparameters\n",
    "\n",
    "2. **Deployment**: The trained model can be:\n",
    "   - Downloaded and used locally\n",
    "   - Deployed to cloud services\n",
    "   - Integrated into applications\n",
    "\n",
    "3. **Further Training**: You can continue training by loading the saved model:\n",
    "   ```python\n",
    "   model = RFDETRMedium.load_model(\"rf_detr_drone_detection.pth\")\n",
    "   model.train(dataset_dir=dataset_location, epochs=5)  # Continue training\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
